import asyncio
import logging
import time
import json
from typing import List, Dict
from app.utils.ai_utils import expand_info_query, generate_info_answer
from app.utils.semantic_search import search_similar_items_enhanced_optimized
from app.config.settings import MAX_CONTEXT_ITEMS
from concurrent.futures import ThreadPoolExecutor

logger = logging.getLogger(__name__)
executor = ThreadPoolExecutor(max_workers=10)


async def process_info_search(user_id: str, query: str, timings: Dict) -> Dict:
    """ì •ë³´ ê²€ìƒ‰ ì²˜ë¦¬"""
    # ì¿¼ë¦¬ í™•ì¥
    query_expand_start = time.time()
    expanded_queries = await expand_info_query(query)
    timings["query_expansion"] = time.time() - query_expand_start
    logger.info(f"ğŸ” í™•ì¥ëœ ì¿¼ë¦¬: {expanded_queries}")

    # ë²¡í„° ê²€ìƒ‰ìœ¼ë¡œ ê´€ë ¨ ì •ë³´ ì°¾ê¸°
    vector_search_start = time.time()
    namespace = f"{user_id}_information"
    loop = asyncio.get_event_loop()

    logger.info(
        f"ğŸ” ë²¡í„° ê²€ìƒ‰ ì‹œì‘ - namespace: {namespace}, queries: {expanded_queries}"
    )

    # ê²€ìƒ‰ ë¡œì§
    context_info = await perform_vector_search(user_id, expanded_queries, query)

    timings["vector_search"] = time.time() - vector_search_start
    logger.info(
        f"ğŸ“š ê²€ìƒ‰ëœ ì •ë³´: {len(context_info)}ê°œ ({timings['vector_search']:.3f}ì´ˆ)"
    )

    # ë‹µë³€ ìƒì„±
    answer_start = time.time()
    answer = await generate_info_answer(user_id, query, context_info)
    timings["answer_generation"] = time.time() - answer_start
    logger.info(f"âœï¸ ë‹µë³€ ìƒì„± ì™„ë£Œ ({timings['answer_generation']:.3f}ì´ˆ)")

    # ê²°ê³¼ êµ¬ì„±
    return {
        "type": "info_search",
        "query": query,
        "answer": answer,
        "context_count": len(context_info),
        "photo_ids": [],
        "_timings": timings,
        "_debug": {
            "expanded_queries": expanded_queries,
            "namespace": namespace,
            "context_sample": (
                context_info[0].get("text", "")[:200] if context_info else None
            ),
        },
    }


async def perform_vector_search(
    user_id: str, expanded_queries: List[str], original_query: str
) -> List[Dict]:
    """ë²¡í„° ê²€ìƒ‰ ìˆ˜í–‰"""
    context_info = []
    loop = asyncio.get_event_loop()

    try:
        # 1. í™•ì¥ëœ ì¿¼ë¦¬ë¡œ ê²€ìƒ‰
        result1 = await loop.run_in_executor(
            executor,
            search_similar_items_enhanced_optimized,
            user_id,
            expanded_queries,
            "information",
            20,
        )
        context_info.extend(result1)
        logger.info(f"âœ… í™•ì¥ëœ ì¿¼ë¦¬ ê²°ê³¼: {len(result1)}ê°œ")

        # 2. ì›ë³¸ ì¿¼ë¦¬ë¡œë„ ê²€ìƒ‰
        if len(context_info) < 5:
            result2 = await loop.run_in_executor(
                executor,
                search_similar_items_enhanced_optimized,
                user_id,
                [original_query],
                "information",
                10,
            )
            context_info.extend(result2)
            logger.info(f"âœ… ì›ë³¸ ì¿¼ë¦¬ ê²°ê³¼: {len(result2)}ê°œ")

        # ì¤‘ë³µ ì œê±°
        seen_texts = set()
        unique_results = []
        for item in context_info:
            text = item.get("text", "")
            if text and text not in seen_texts:
                seen_texts.add(text)
                unique_results.append(item)

        return unique_results[:MAX_CONTEXT_ITEMS]

    except Exception as e:
        logger.error(f"âŒ ë²¡í„° ê²€ìƒ‰ ì‹¤íŒ¨: {str(e)}", exc_info=True)
        return []
