import asyncio
import logging
import time
import json
from typing import Dict, List
from app.utils.ai_utils import generate_conversation_response
from app.utils.async_utils import save_query_async, save_result_async
from app.utils.chat_vector_store import search_chat_history
from app.utils.context_helpers import check_if_requires_context, generate_contextualized_conversation_response

logger = logging.getLogger(__name__)


def check_if_requires_context(query: str) -> bool:
    """ì§ˆë¬¸ì´ ë§¥ë½ì´ í•„ìš”í•œì§€ ê²„ë‹¨íˆ í™•ì¸"""
    # ì‚¬ìš©ì ì •ë³´ë‚˜ ì´ì „ ëŒ€í™”ë¥¼ ì°¸ì¡°í•˜ëŠ” í‚¤ì›Œë“œ
    context_keywords = [
        # ì´ì „ ëŒ€í™” ì°¸ì¡°
        "ì´ì „", "ì•„ê¹Œ", "ë°©ê¸ˆ", "ê·¸ë•Œ", "ë‹¤ì‹œ", "ê·¸ê±°", "ê·¸ê²ƒ", "ì €ë²ˆì—", "ì–´ì œ", "ì§€ë‚œ", "ì „ì—",
        # ê°œì¸ ì„ í˜¸ë„ ì°¸ì¡°
        "ì¢‹ì•„í•˜", "ì¢‹ì•„í•´", "ì¢‹ì•„", "ì¢‹ì€", "ì„ í˜¸í•˜", "ì„ í˜¸ë„", "ì¢‹ì•„í•˜ëŠ”", "ìš°ë¦¬", "ìš°ë¦¬ëŠ”", "ìš°ë¦¬ê°€", "ìš°ë¦¬ì˜",
        # ì†Œìœ ë¥¼ ë‚˜íƒ€ë‚´ëŠ” í‘œí˜„
        "ë‚´", "ë‚˜ì˜", "ë‚˜ëŠ”", "ë‚´ê°€", "ë‚´ê°€ ì¢‹ì•„í•˜ëŠ”", "ë‚´ ì¢‹ì•„í•˜ëŠ”", "ë‚´ê°€ ì„ í˜¸í•˜ëŠ”", "ë‚´ ì„ í˜¸í•˜ëŠ”",
        # ê´€ì‹¬ì‚¬/ì·¨ë¯¸ ê´€ë ¨
        "ì·¨ë¯¸", "ì·¨ë¯¸ëŠ”", "ì·¨ë¯¸ê°€", "ê´€ì‹¬ì‚¬", "ê´€ì‹¬", "ê´€ì‹¬ìˆ", "ì—¬ê°€", "ì—¬ê°€ëŠ”", "ì—¬ê°€ê°€",
        # ìŒì‹/ìƒˆìš°ì‹í’ˆ ê´€ë ¨
        "ìŒì‹", "ìŒì‹ì€", "ìŒì‹ì„", "ìŒì‹ì´", "ìŒì‹ì€", "ë¨¹ì„", "ë¨¹ëŠ”", "ì¦ê²¨ë¨¹", "ì¦ê²¨",
    ]
    
    # ì‚¬ìš©ì ì •ë³´ë‚˜ ì´ì „ ëŒ€í™”ì— ëŒ€í•œ ì§ˆë¬¸ ì—¬ë¶€
    query_lower = query.lower()
    return any(keyword in query_lower for keyword in context_keywords)


async def process_conversation(user_id: str, query: str, timings: Dict) -> Dict:
    """ëŒ€í™”í˜• ë©”ì‹œì§€ ì²˜ë¦¬ - ì‚¬ìš©ìì˜ ì´ì „ ëŒ€í™” ê¸°ë¡ í™œìš©"""
    
    # ëŒ€í™” ë§¥ë½ì„ í•„ìš”ë¡œ í•˜ëŠ”ì§€ ë¶„ì„
    requires_context = check_if_requires_context(query)
    chat_history = []
    
    if requires_context:
        # ì´ì „ ëŒ€í™” ê¸°ë¡ ê²€ìƒ‰
        context_start = time.time()
        chat_history = search_chat_history(user_id, query, top_k=5)
        
        # ì´ì „ ëŒ€í™”ë¥¼ ì‹œê°„ìˆœìœ¼ë¡œ ì •ë ¬
        chat_history.sort(key=lambda x: x.get("timestamp", 0))
        
        timings["context_retrieval"] = time.time() - context_start
        logger.info(f"ğŸ” ì´ì „ ëŒ€í™” ê²€ìƒ‰: {len(chat_history)}ê°œ ({timings['context_retrieval']:.3f}ì´ˆ)")
    
    # ëŒ€í™”í˜• ì‘ë‹µ ìƒì„±
    response_start = time.time()
    
    if chat_history:
        # ë§¥ë½ì´ ìˆëŠ” ê²½ìš° - ìƒˆë¡œìš´ í•¨ìˆ˜ ì‚¬ìš©
        response, used_history = await generate_contextualized_conversation_response(user_id, query, chat_history)
        logger.info(f"ğŸ’¬ ë§¥ë½ ê¸°ë°˜ ëŒ€í™” ì‘ë‹µ ìƒì„± (ì‚¬ìš©ëœ ê¸°ë¡: {len(used_history)}ê°œ)")
    else:
        # ë§¥ë½ì´ ì—†ëŠ” ê²½ìš° - ê¸°ì¡´ í•¨ìˆ˜ ì‚¬ìš©
        response = await generate_conversation_response(user_id, query)
        used_history = []
        logger.info("ğŸ’¬ ì¼ë°˜ ëŒ€í™” ì‘ë‹µ ìƒì„±")
        
    timings["conversation_response"] = time.time() - response_start
    logger.info(f"ğŸ’¬ ëŒ€í™” ì‘ë‹µ ìƒì„± ì™„ë£Œ ({timings['conversation_response']:.3f}ì´ˆ)")

    # ê²°ê³¼ êµ¬ì„±
    return {
        "type": "conversation",
        "query": query,
        "answer": response,
        "context_used": len(used_history) > 0,  # ë§¥ë½ ì‚¬ìš© ì—¬ë¶€
        "photo_ids": [],  # ë¹ˆ ë°°ì—´ ìœ ì§€
        "_timings": timings,
        "_debug": {
            "context_count": len(chat_history),
            "history_used": used_history,
        } if chat_history else {},
    }
