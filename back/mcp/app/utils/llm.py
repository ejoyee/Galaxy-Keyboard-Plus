import os
import json
import logging
from openai import OpenAI
from openai import AsyncOpenAI
from dotenv import load_dotenv

# ë¡œê·¸ ì´ˆê¸°í™”
logger = logging.getLogger(__name__)

load_dotenv()
client = AsyncOpenAI(api_key=os.getenv("OPENAI_API_KEY"))


def format_tools_for_openai(tools_info):
    tool_list = []
    for srv, tools in tools_info.items():
        for tool in tools:
            tool_list.append(
                {
                    "type": "function",
                    "function": {
                        # ë°˜ë“œì‹œ MCP ì„œë²„ëª…_íˆ´ëª…ìœ¼ë¡œ ì´ë¦„ ìƒì„±!
                        "name": f"{srv}_{tool['name']}",
                        "description": tool.get("description", ""),
                        "parameters": tool.get("inputSchema", {}),
                    },
                }
            )
    return tool_list
    # [
    #   {"type": "function", "function": {"name": "brave_brave_web_search", ...}},
    #   {"type": "function", "function": {"name": "brave_brave_local_search", ...}}
    # ]


async def call_llm(query: str, tools_info: dict, settings=None) -> dict:

    # tools_info: {"brave": [tool, tool, ...], ...}
    tools = format_tools_for_openai(tools_info)

    system_prompt = """
    You are a specialized agent that transforms user requests into calls to the registered MCP tools, or else returns plain-text answers.

    Guidelines:
    1. TOOL CALL
        â€¢ If a request requires tool access (web search, etc.), emit exactly one tool call JSON with the correct tool name and all required parameters.
        â€¢ Use only the provided tool names and schemasâ€”do not invent new tools or free-form code.
    2. TEXT RESPONSE
        â€¢ If the request can be satisfied without a tool call, reply with natural-language text and do not call any tool.
    3. FOLLOW-UP QUESTIONS
        â€¢ If a required parameter is missing or ambiguous, ask the user a clarifying question instead of guessing.
    4. NO EXTRA VERBIAGE
        â€¢ When calling a tool, respond with strictly the function call objectâ€”no explanatory text.
        â€¢ Any human-readable explanation should only appear in plain-text responses when no tool is invoked.
    """
    response = await client.chat.completions.create(
        model="gpt-4o-mini",
        messages=[
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": query},
        ],
        tools=tools,
        tool_choice="auto",
        max_tokens=1024,
    )

    """
    "message": {
        "roe": "assistant",
            "content": "2024ë…„ ì¸ê³µì§€ëŠ¥ì˜ ìµœì‹  ë™í–¥ì€ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤: ...",
        // tool_calls ì—†ìŒ!
    }
    "message": {
        "role": "assistant",
        "content": null,  // í…ìŠ¤íŠ¸ ë‹µë³€ì€ ì—†ìŒ
        "tool_calls": [
          {
            "id": "call_abc123",
            "type": "function",
            "function": {
              "name": "brave_web_search",
              "arguments": "{\"query\": \"ì¸ê³µì§€ëŠ¥ ìµœì‹  ë™í–¥\", \"limit\": 5}"
            }
          }
        ]
    }
    """

    msg = response.choices[0].message

    # ----- 1. tool_calls íŒŒì‹± -----
    tool_calls = getattr(msg, "tool_calls", None)
    if tool_calls and isinstance(tool_calls, list) and tool_calls:
        fc = tool_calls[0].function
    else:
        fc = None

    # ----- 2. íˆ´ í˜¸ì¶œ ì—†ìœ¼ë©´ í…ìŠ¤íŠ¸ ì‘ë‹µ -----
    if not fc or not hasattr(fc, "arguments"):
        return {"type": "text", "content": msg.content or ""}

    # ----- 3. arguments JSON íŒŒì‹± -----
    try:
        arguments = fc.arguments
        parsed = json.loads(arguments) if isinstance(arguments, str) else arguments
    except Exception:
        logger.error(
            f"Failed to parse tool arguments: {getattr(fc, 'arguments', None)}"
        )
        return {"type": "text", "content": msg.content or ""}

    params = parsed.get("params", parsed)

    # ----- 4. tool nameì—ì„œ ì„œë²„ëª…/íˆ´ëª… ì¶”ì¶œ -----
    alias = fc.name
    try:
        srvId, method = alias.split("_", 1)
    except Exception:
        logger.error(f"Invalid tool alias format: {alias}")
        return {"type": "text", "content": msg.content or ""}

    # ----- 5. ìµœì¢… ê²°ê³¼ ë°˜í™˜ -----
    return {
        "type": "rpc",
        "srvId": srvId,
        "method": method,
        "params": params,
    }


async def summarize_with_llm(rpc_result: dict, prompt: str = "", settings=None) -> dict:
    """
    MCP íˆ´ í˜¸ì¶œ ê²°ê³¼ë¥¼ OpenAIë¡œ í•œê¸€ ìì—°ì–´ ìš”ì•½
    - rpc_result: MCP ì„œë²„ì—ì„œ ë°›ì€ raw ê²°ê³¼ (dict)
    - prompt: ì›ë˜ ì‚¬ìš©ìì˜ ì§ˆë¬¸ (optional, ìˆìœ¼ë©´ ë” ìì—°ìŠ¤ëŸ½ê²Œ ìš”ì•½ ê°€ëŠ¥)
    """

    # 1. rawResult ì¶”ì¶œ
    #   - rpc_result["content"]ê°€ listë©´ type=text ì¸ ê²ƒë§Œ ê³¨ë¼ textë¥¼ ì´ì–´ë¶™ì„
    #   - ì•„ë‹ˆë©´ ê·¸ëƒ¥ ì „ì²´ë¥¼ jsonìœ¼ë¡œ ì§ë ¬í™”
    if isinstance(rpc_result, dict) and isinstance(rpc_result.get("content"), list):
        rawResult = "\n".join(
            c.get("text", "") for c in rpc_result["content"] if c.get("type") == "text"
        )
    else:
        rawResult = json.dumps(rpc_result, ensure_ascii=False, indent=2)

    # 2. ìš”ì•½ìš© system/user/assistant í”„ë¡¬í”„íŠ¸ êµ¬ì„±
    system_prompt = (
        "You are a helpful assistant. The user made a request, "
        "we ran a filesystem tool and got some raw output. "
        "Now produce a single, concise, natural-language response "
        "that explains the result to the user. "
        "ë‹µë³€ì€ í•œê¸€ë¡œ í•´ì£¼ì„¸ìš”."
    )

    messages = [
        {"role": "system", "content": system_prompt},
    ]
    if prompt:
        messages.append({"role": "user", "content": f"Original request:\n{prompt}"})
    messages.append({"role": "assistant", "content": f"Tool output:\n{rawResult}"})

    # 3. OpenAI ìš”ì•½ í˜¸ì¶œ
    response = await client.chat.completions.create(
        model="gpt-4o-mini",
        messages=messages,
        max_tokens=1024,
        temperature=0.4,
    )
    friendly = response.choices[0].message.content.strip()

    # 4. ë°˜í™˜
    return {"results": [{"description": friendly}]}


import re


async def call_llm_for_airbnb(query: str) -> dict:
    """
    Airbnb ìì—°ì–´ ì¿¼ë¦¬ë¥¼ MCP íˆ´ í˜¸ì¶œ í¬ë§·ìœ¼ë¡œ ë³€í™˜
    """
    system_prompt = """
    ì‚¬ìš©ìì˜ ìˆ™ì†Œ ê²€ìƒ‰ ìš”ì²­ì„ ë¶„ì„í•´ì„œ MCP íˆ´ í˜¸ì¶œ JSONìœ¼ë¡œ ë³€í™˜í•˜ì„¸ìš”.

    ì¡°ê±´:
    - MCP ì„œë²„: airbnb-mcp
    - íˆ´ ì´ë¦„: airbnb_search
    - ë°˜í™˜ í˜•ì‹ ì˜ˆì‹œ:
    {
        "type": "rpc",
        "srvId": "airbnb-mcp",
        "method": "airbnb_search",
        "params": {
            "location": "ë¶€ì‚°",
            "checkin": "2025-05-30",
            "checkout": "2025-06-01",
            "adults": 2
        }
    }
    - ë‚ ì§œ, ì¸ì›ìˆ˜, ìœ„ì¹˜ëŠ” ìì—°ì–´ë¡œ ì…ë ¥ë˜ë”ë¼ë„ ê°€ëŠ¥í•œ ì •í™•íˆ ì¶”ë¡ í•˜ì„¸ìš”.
    - ì •ë³´ê°€ ë¶€ì¡±í•œ ê²½ìš° ê¸°ë³¸ê°’ì„ ì“°ë˜, ëª…í™•í•˜ì§€ ì•Šìœ¼ë©´ tool í˜¸ì¶œ ì—†ì´ ìì—°ì–´ë¡œ ë‹µí•˜ì„¸ìš”.
    - í•œê¸€ë¡œ ëœ ìì—°ì–´ ìš”ì²­ì„ ì´í•´í•˜ì„¸ìš”.
    """

    messages = [
        {"role": "system", "content": system_prompt},
        {"role": "user", "content": query},
    ]

    response = await client.chat.completions.create(
        model="gpt-4o-mini",
        messages=messages,
        max_tokens=1024,
        temperature=0.2,
    )

    msg = response.choices[0].message
    content = msg.content.strip()

    # ì½”ë“œë¸”ëŸ­ ì•ˆì˜ JSON ì¶”ì¶œ ì‹œë„
    try:
        # 1. ì½”ë“œ ë¸”ë¡ ì•ˆ JSON ì¶”ì¶œ
        json_match = re.search(r"```json\s*(\{.*?\})\s*```", content, re.DOTALL)
        if json_match:
            raw_json = json_match.group(1)
            result = json.loads(raw_json)
        else:
            # 2. ì½”ë“œ ë¸”ë¡ ì—†ì´ ì§ì ‘ JSON ì‘ë‹µ
            result = json.loads(content)

        # 3. âœ… srvId ì •ì •
        if result.get("type") == "rpc":
            result["srvId"] = "airbnb"

        return result

    except Exception:
        logger.warning("ğŸ”´ Airbnb ì „ìš© LLM í˜¸ì¶œ ê²°ê³¼ íŒŒì‹± ì‹¤íŒ¨")
        return {"type": "text", "content": content or "ë‹µë³€ì„ ì´í•´í•˜ì§€ ëª»í–ˆì–´ìš”."}
