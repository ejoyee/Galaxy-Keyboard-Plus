## LLM 및 RAG 사전 학습

### 1. LLM (Large Language Model)
📌 개념
- 대규모 텍스트 데이터를 바탕으로 학습한 자연어 처리 인공지능 모델
- 사람처럼 문장을 이해하고 생성 가능.
- ex) GPT(openAI), BERT(Google), LLaMA(Meta), Claude(Anthropic)

### 2. RAG (Retrieval-Augumented Generation)
📌 개념
- **검색 (Retrieval)** 과 **생성(Generation)**을 결합한 방식
- LLM이 답변을 생성하기 전에, 외부 지식소스(문서, DB ..)에서 관련 정보를 검색해 더 정확한 응답 생성 가능

🌟 RAG 단계
1. **Load**(문서 로드) : 문서(pdf, word), RAW DATA, 웹페이지, Notion 등의 데이터를 읽기
2. **Split**(분할) : 불러온 문서를 **chunk** 단위로 분할
3. **Embedding**(임베딩) : 문서를 벡터 표현으로 변환
4. **Store**(벡터 DB 저장) : 변환된 벡터를 DB에 저장
5. **Retrieval**(검색) : 유사도 검색
6. **Prompt**(프롬프트) : 검색된 결과를 바탕으로 원하는 결과를 도출하기 위한 프롬프트
7. **LLM**(모델) : openai(LLM) 모델 선택
8. **Output**(결과) : 텍스트, JSON, Markdown

### 3. 임베딩 벡터
📌 개념
- 임베딩(Embedding)이란? 단어, 문장, 이미지, 문서 등 비정형 데이터를 고차원 숫자 벡터로 변환하는 기술 => 이때 만들어진 숫자 배열을 **임베딩 벡터(Embedding Vector)**라고 함.
- 사람이 이해하는 문장을 컴퓨터가 이해할 수 있게 숫자로 바꾸는 과정

### 4. RAG 실습
📦 1. 필요한 모듈 설치
```
pip install langchain langchain-core langchain-community langchain-openai langchain-text-splitters faiss-cpu PyMuPDF python-dotenv openai
```

📂 2. 라이브러리 불러오기
```
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_community.document_loaders import PyMuPDFLoader
from langchain_community.vectorstores import FAISS
from langchain_core.output_parsers import StrOutputParser
from langchain_core.runnables import RunnablePassthrough
from langchain_core.prompts import PromptTemplate
from langchain_openai import ChatOpenAI, OpenAIEmbeddings

# .env 파일에 저장된 환경변수(OPENAI_API_KEY)를 Python 코드로 불러오는 도구
from dotenv import load_dotenv
load_dotenv()
```

📜 3. 문서 로드 (Load Documents)
```
loader = PyMuPDFLoader("data/SPRI_AI_Brief_2023년12월호_F.pdf")
docs = loader.load()
```

🪓 4. 문서 분할(Split Documents)
```
# chunk_size : 문단의 분할 수
# chunk_overlap : 분할하는 부분에서 겹치는 글자의 수
text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)
split_documents = text_splitter.split_documents(docs)
```

🧠 5. 임베딩(Embedding) 생성
```
embeddings = OpenAIEmbeddings()
```

🥫 6. DB 생성(Create DB) 및 저장
```
# 벡터스토어를 생성합니다.
vectorstore = FAISS.from_documents(documents=split_documents, embedding=embeddings)
```

🔍 7. 검색기(Retriever) 생성
```
# 문서에 포함되어 있는 정보를 검색하고 생성합니다.
retriever = vectorstore.as_retriever()
```

✍🏻 8. 프롬프트 생성(Create Prompt)
```
prompt = PromptTemplate.from_template(
    """You are an assistant for question-answering tasks. 
Use the following pieces of retrieved context to answer the question. 
If you don't know the answer, just say that you don't know. 
Answer in Korean.

#Context: 
{context}

#Question:
{question}

#Answer:"""
)
```

🗨️ 9. 언어모델(LLM) 생성
```
llm = ChatOpenAI(model_name="gpt-4o", temperature=0)
```

⛓️‍💥 10. 체인(Chain) 생성 및 실행
```
chain = (
    {"context": retriever, "question": RunnablePassthrough()}
    | prompt
    | llm
    | StrOutputParser()
)
question = "삼성전자가 자체 개발한 AI 의 이름은?"
response = chain.invoke(question)
print(response)
```