## LLM ë° RAG ì‚¬ì „ í•™ìŠµ

### 1. LLM (Large Language Model)
ğŸ“Œ ê°œë…
- ëŒ€ê·œëª¨ í…ìŠ¤íŠ¸ ë°ì´í„°ë¥¼ ë°”íƒ•ìœ¼ë¡œ í•™ìŠµí•œ ìì—°ì–´ ì²˜ë¦¬ ì¸ê³µì§€ëŠ¥ ëª¨ë¸
- ì‚¬ëŒì²˜ëŸ¼ ë¬¸ì¥ì„ ì´í•´í•˜ê³  ìƒì„± ê°€ëŠ¥.
- ex) GPT(openAI), BERT(Google), LLaMA(Meta), Claude(Anthropic)

### 2. RAG (Retrieval-Augumented Generation)
ğŸ“Œ ê°œë…
- **ê²€ìƒ‰ (Retrieval)** ê³¼ **ìƒì„±(Generation)**ì„ ê²°í•©í•œ ë°©ì‹
- LLMì´ ë‹µë³€ì„ ìƒì„±í•˜ê¸° ì „ì—, ì™¸ë¶€ ì§€ì‹ì†ŒìŠ¤(ë¬¸ì„œ, DB ..)ì—ì„œ ê´€ë ¨ ì •ë³´ë¥¼ ê²€ìƒ‰í•´ ë” ì •í™•í•œ ì‘ë‹µ ìƒì„± ê°€ëŠ¥

ğŸŒŸ RAG ë‹¨ê³„
1. **Load**(ë¬¸ì„œ ë¡œë“œ) : ë¬¸ì„œ(pdf, word), RAW DATA, ì›¹í˜ì´ì§€, Notion ë“±ì˜ ë°ì´í„°ë¥¼ ì½ê¸°
2. **Split**(ë¶„í• ) : ë¶ˆëŸ¬ì˜¨ ë¬¸ì„œë¥¼ **chunk** ë‹¨ìœ„ë¡œ ë¶„í• 
3. **Embedding**(ì„ë² ë”©) : ë¬¸ì„œë¥¼ ë²¡í„° í‘œí˜„ìœ¼ë¡œ ë³€í™˜
4. **Store**(ë²¡í„° DB ì €ì¥) : ë³€í™˜ëœ ë²¡í„°ë¥¼ DBì— ì €ì¥
5. **Retrieval**(ê²€ìƒ‰) : ìœ ì‚¬ë„ ê²€ìƒ‰
6. **Prompt**(í”„ë¡¬í”„íŠ¸) : ê²€ìƒ‰ëœ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì›í•˜ëŠ” ê²°ê³¼ë¥¼ ë„ì¶œí•˜ê¸° ìœ„í•œ í”„ë¡¬í”„íŠ¸
7. **LLM**(ëª¨ë¸) : openai(LLM) ëª¨ë¸ ì„ íƒ
8. **Output**(ê²°ê³¼) : í…ìŠ¤íŠ¸, JSON, Markdown

### 3. ì„ë² ë”© ë²¡í„°
ğŸ“Œ ê°œë…
- ì„ë² ë”©(Embedding)ì´ë€? ë‹¨ì–´, ë¬¸ì¥, ì´ë¯¸ì§€, ë¬¸ì„œ ë“± ë¹„ì •í˜• ë°ì´í„°ë¥¼ ê³ ì°¨ì› ìˆ«ì ë²¡í„°ë¡œ ë³€í™˜í•˜ëŠ” ê¸°ìˆ  => ì´ë•Œ ë§Œë“¤ì–´ì§„ ìˆ«ì ë°°ì—´ì„ **ì„ë² ë”© ë²¡í„°(Embedding Vector)**ë¼ê³  í•¨.
- ì‚¬ëŒì´ ì´í•´í•˜ëŠ” ë¬¸ì¥ì„ ì»´í“¨í„°ê°€ ì´í•´í•  ìˆ˜ ìˆê²Œ ìˆ«ìë¡œ ë°”ê¾¸ëŠ” ê³¼ì •

### 4. RAG ì‹¤ìŠµ
ğŸ“¦ 1. í•„ìš”í•œ ëª¨ë“ˆ ì„¤ì¹˜
```
pip install langchain langchain-core langchain-community langchain-openai langchain-text-splitters faiss-cpu PyMuPDF python-dotenv openai
```

ğŸ“‚ 2. ë¼ì´ë¸ŒëŸ¬ë¦¬ ë¶ˆëŸ¬ì˜¤ê¸°
```
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_community.document_loaders import PyMuPDFLoader
from langchain_community.vectorstores import FAISS
from langchain_core.output_parsers import StrOutputParser
from langchain_core.runnables import RunnablePassthrough
from langchain_core.prompts import PromptTemplate
from langchain_openai import ChatOpenAI, OpenAIEmbeddings

# .env íŒŒì¼ì— ì €ì¥ëœ í™˜ê²½ë³€ìˆ˜(OPENAI_API_KEY)ë¥¼ Python ì½”ë“œë¡œ ë¶ˆëŸ¬ì˜¤ëŠ” ë„êµ¬
from dotenv import load_dotenv
load_dotenv()
```

ğŸ“œ 3. ë¬¸ì„œ ë¡œë“œ (Load Documents)
```
loader = PyMuPDFLoader("data/SPRI_AI_Brief_2023ë…„12ì›”í˜¸_F.pdf")
docs = loader.load()
```

ğŸª“ 4. ë¬¸ì„œ ë¶„í• (Split Documents)
```
# chunk_size : ë¬¸ë‹¨ì˜ ë¶„í•  ìˆ˜
# chunk_overlap : ë¶„í• í•˜ëŠ” ë¶€ë¶„ì—ì„œ ê²¹ì¹˜ëŠ” ê¸€ìì˜ ìˆ˜
text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)
split_documents = text_splitter.split_documents(docs)
```

ğŸ§  5. ì„ë² ë”©(Embedding) ìƒì„±
```
embeddings = OpenAIEmbeddings()
```

ğŸ¥« 6. DB ìƒì„±(Create DB) ë° ì €ì¥
```
# ë²¡í„°ìŠ¤í† ì–´ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
vectorstore = FAISS.from_documents(documents=split_documents, embedding=embeddings)
```

ğŸ” 7. ê²€ìƒ‰ê¸°(Retriever) ìƒì„±
```
# ë¬¸ì„œì— í¬í•¨ë˜ì–´ ìˆëŠ” ì •ë³´ë¥¼ ê²€ìƒ‰í•˜ê³  ìƒì„±í•©ë‹ˆë‹¤.
retriever = vectorstore.as_retriever()
```

âœğŸ» 8. í”„ë¡¬í”„íŠ¸ ìƒì„±(Create Prompt)
```
prompt = PromptTemplate.from_template(
    """You are an assistant for question-answering tasks. 
Use the following pieces of retrieved context to answer the question. 
If you don't know the answer, just say that you don't know. 
Answer in Korean.

#Context: 
{context}

#Question:
{question}

#Answer:"""
)
```

ğŸ—¨ï¸ 9. ì–¸ì–´ëª¨ë¸(LLM) ìƒì„±
```
llm = ChatOpenAI(model_name="gpt-4o", temperature=0)
```

â›“ï¸â€ğŸ’¥ 10. ì²´ì¸(Chain) ìƒì„± ë° ì‹¤í–‰
```
chain = (
    {"context": retriever, "question": RunnablePassthrough()}
    | prompt
    | llm
    | StrOutputParser()
)
question = "ì‚¼ì„±ì „ìê°€ ìì²´ ê°œë°œí•œ AI ì˜ ì´ë¦„ì€?"
response = chain.invoke(question)
print(response)
```