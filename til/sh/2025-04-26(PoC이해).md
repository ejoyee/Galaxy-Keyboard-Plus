# 2025-04-26(PoC 이해)

# PoC 이해

## MCP Client - LLM 흐름

```jsx
[ MCP 서버 띄움 ]
     ↓ 
[ Main 프로세스 MCP 툴 목록 준비 ]
     ↓ 
[ OpenAI GPT 호출 ]
     ↓
[ LLM: "이 툴 써야겠다" 판단 ]
     ↓ 
[ Main 프로세스: tool_calls 해석 ]
     ↓
[ MCP 서버에 JSON-RPC 호출 (실제 작업) ]
     ↓
[ 결과 받아서 사용자에게 ]
```

### 1. 여러 MCP 서버에서 툴 목록 가져오기

처음 Electron Main 프로세스가 서버를 띄울 때,
MCP 서버마다 `list_tools` 명령을 보내서 툴 목록을 받아오기

```jsx
const tools = await rpc.call("list_tools");
```

그리고 이걸 모두 모으기

```jsx
function allTools() {
  return servers.flatMap((s) => s.tools);
}
```

> 예를 들면:
> 
> - Filesystem MCP 서버 ➔ `read_file`, `list_directory`
> - Gmail MCP 서버 ➔ `send_email`, `search_email`

**(== "현재 내가 쓸 수 있는 MCP 기능들" 리스트)**

---

### 2. MCP tools 리스트를 LLM (GPT) 호출할 때 넘긴다

OpenAI API 요청에 **`tools`** 필드로 MCP 목록을 함께 보내기

```jsx
const res = await axios.post("https://api.openai.com/v1/chat/completions", {
  model: "gpt-4o-mini",
  messages: [...],
  tools: allTools().map(formatToolV2), // 📌 여기!!
  tool_choice: "auto" // 📌 여기!!
});
```

여기서 중요:

| 필드 | 역할 |
| --- | --- |
| `tools` | 쓸 수 있는 MCP 툴 전체 목록 전달 |
| `tool_choice: "auto"` | GPT가 **스스로 어떤 MCP를 선택**할 수 있도록 허용 |

---

### 3. LLM이 "어떤 MCP 툴을 쓸지" 스스로 결정

OpenAI GPT-4o-mini 같은 LLM은 이 받은 tools 목록을 읽고,
**사용자의 자연어 요청을 해석해서**:

- "아, 이건 파일 시스템에서 파일 읽는 거네 → fs_read_file 호출!"
- "아, 이건 이메일 보내는 거네 → gmail_send_email 호출!"

**이렇게 스스로 MCP 툴을 고름**

그리고 응답으로 **tool_calls 넘김**:

```json
{
  "tool_calls": [
    {
      "function": {
        "name": "fs_read_file",
        "arguments": "{\"path\": \"./readme.txt\"}"
      }
    }
  ]
}
```

**tool_calls에서 `name`이 어떤 MCP를 쓸지 표시!**

---

### 4. Electron Main 프로세스는 이 선택을 보고 실제 호출

Electron은 tool_calls 결과를 보고:

- "아, LLM이 fs_read_file을 쓰고 싶어 하는구나"
- "그럼 Filesystem MCP 서버에 `call_tool`로 보내야겠다"

라고 해서 MCP 서버에 직접 호출을 보냄.

```jsx
await srv.rpc.call("call_tool", { name: method, arguments: params });
```

---

### 전체 흐름 그림으로 요약

```
[ MCP 서버 1, MCP 서버 2, MCP 서버 3 띄움 ]
       ↓ list_tools
[ 모든 MCP tools 모아서 LLM에게 넘김 (OpenAI tools 필드) ]
       ↓
[ LLM이 사용자의 자연어 명령 해석 ]
       ↓
[ "이 요청은 fs_read_file 써야겠다!" 판단 (tool_call) ]
       ↓
[ Electron Main이 MCP 서버에 실제 호출 ]
       ↓
[ 결과를 받아서 사용자에게 반환 ]
```

---

### ✅포인트

| 질문 | 답변 |
| --- | --- |
| 어떤 MCP를 쓸지는 누가 정함? | ➡️ LLM (GPT, Claude 등) |
| Main 프로세스는 뭘 하냐? | ➡️ LLM에게 MCP tools 목록을 넘기고, 선택 결과(tool_call)를 받아 실제 호출만 함 |
| 강제로 특정 MCP를 쓰게 할 수 있나? | ➡️ 가능은 한데, 이 기본 흐름에서는 LLM이 자율적으로 판단 |

## MCP 서버 띄우기

### 0. MCP 서버를 설치

- root/.bin 안에 서버 관련 파일 존재하는 상태

### 1. 어떤 MCP 서버를 띄울지 정의

```jsx
const SERVER_DEFS = [
  {
    id: "fs", // 서버 고유 id
    name: "Filesystem", // 서버 이름
    bin: process.platform === "win32" ? "mcp-server-filesystem.cmd" : "mcp-server-filesystem", // 실행 파일 이름
    allowedDir: process.cwd(), // 파일 시스템 MCP 서버라 기본 접근 디렉토리 지정
  },
];
```

**✅ 요약:**

- `id`: 이 서버를 식별하는 고유 id (`fs`, `gmail`, `calendar` 같은)
- `bin`: 실행할 바이너리 파일 이름
- `allowedDir`: (filesystem MCP 서버의 경우) 파일 작업 허용 경로

---

### 2. 실제로 MCP 서버를 띄우는 함수

```jsx
async function spawnServer(def) {
  const binPath = path.join(__dirname, "node_modules", ".bin", def.bin);
  if (!fs.existsSync(binPath)) {
    err("not found", binPath);
    return null;
  }

  const proc = spawn(binPath, [def.allowedDir], {
    cwd: def.allowedDir,
    stdio: ["pipe", "pipe", "pipe"], // stdin, stdout, stderr 다 파이프 연결
  });

  const rpc = new StdioRPCClient(proc, def.id);
  const srv = { ...def, proc, rpc, tools: [] };

  await refreshTools(srv); // MCP 서버에 연결해서 list_tools 호출

  servers.push(srv); // 띄운 서버를 서버 리스트에 저장

  aliasMap.clear(); // 서버 툴 이름 매핑 갱신

  return srv;
}
```

### 여기서 중요한 포인트:

| 코드 | 설명 |
| --- | --- |
| `spawn(binPath, [def.allowedDir])` | MCP 서버를 별도 프로세스로 띄운다. (allowedDir을 인자로 넘겨줌) |
| `stdio: ["pipe", "pipe", "pipe"]` | stdin, stdout, stderr 모두 연결해서 프로그램과 대화 가능하게 만듬 |
| `new StdioRPCClient(proc, def.id)` | MCP 서버와 JSON-RPC 통신할 클라이언트 객체를 만든다. |
| `refreshTools(srv)` | MCP 서버한테 "너 어떤 기능(tool) 제공해?" 하고 물어본다. |
| `servers.push(srv)` | 서버 목록에 등록해서 이후에 툴 호출할 때 쓸 수 있게 만든다. |

---

### MCP 서버 띄우는 흐름을 아주 쉽게 요약하면

```
MCP 서버 실행 파일 경로 찾기
    ↓
child_process.spawn() 으로 실행
    ↓
stdin, stdout, stderr 파이프 연결
    ↓
JSON-RPC 클라이언트 세팅
    ↓
서버한테 list_tools 요청해서 지원 기능 불러오기
    ↓
서버 리스트에 추가해서 관리
```

---

### 실전적으로 중요한 점

- **spawn으로 띄우는 MCP 서버는 살아 있는 프로세스야.**
    - MCP 서버가 죽으면 다시 띄워야 해 (watchdog 가능)
- **stdin/stdout으로 대화하는 구조라서, HTTP 서버랑은 좀 달라.**
- **띄울 때 디렉토리 권한(allowedDir)을 잘 설정해줘야 파일 접근 에러가 안 난다.**

---

### 그림으로 요약

```
[Electron Main Process]
   ↓ spawn()
[Filesystem MCP Server 프로세스 실행]
   ↓
[stdin/stdout 연결]
   ↓
[JSON-RPC 통신 준비 완료]
   ↓
[list_tools 호출해서 사용 가능한 MCP 기능 파악]
   ↓
[Electron이 이 서버를 사용 가능한 상태로 관리]
```