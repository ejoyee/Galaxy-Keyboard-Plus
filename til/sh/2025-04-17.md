# 2025-04-17

# RAG 기술 이론 정리

## 🔍 1. RAG란 무엇인가?

**RAG (Retrieval-Augmented Generation)**

: 생성형 AI가 **정확하고 신뢰할 수 있는 답변을 만들 수 있도록**, 외부 문서를 검색(Retrieval)해서 그 내용을 바탕으로 답변을 생성(Generation)하는 기술

### 🎯 왜 필요한가요?

- LLM은 내부 지식이 제한됨 (최신 정보 부족, 망각 등)
- RAG는 외부 문서(DB, PDF, 웹 등)를 검색해 답변을 "보강"함

---

## 🧠 2. RAG 구성 요소

| 단계 | 설명 |
| --- | --- |
| **① Split** | 큰 문서를 작고 의미 있는 단위로 나눔 |
| **② Embedding** | 텍스트를 의미 기반 벡터로 변환 |
| **③ Vector Store** | 임베딩 벡터를 저장하고 빠르게 검색 |
| **④ Retrieval** | 사용자 질문과 유사한 벡터(문장) 검색 |
| **⑤ Generation** | 검색된 문서를 참고해 LLM이 응답 생성 |

📌 이 흐름을 통해 RAG는 "정보 기반의 정확한 생성형 응답"을 가능하게 합니다.

---

## 🧰 3. LangChain과의 관계

**LangChain**은 RAG를 비롯한 여러 LLM 도구들을 **조립하고 연결하는 프레임워크**입니다.

### 🔗 역할:

- Split, Embedding, Vector Store, Retrieval, Generation 등을 손쉽게 연결
- 다양한 라이브러리(FAISS, Hugging Face, OpenAI 등) 통합
- LangChain으로 **RAG 시스템을 매우 간단하게 구현** 가능

예: `RetrievalQA`, `ConversationalRetrievalChain`

📌 즉, **LangChain은 RAG를 실제로 구현하고 운용하는 실무형 엔진**입니다.

---

## 🧩 4. MCP와의 관계

**MCP (Multi-Chain Prompting)**

: 하나의 질문을 여러 단계 또는 관점으로 나눠, **깊이 있는 사고와 분석형 응답을 생성**하는 전략

### 🔍 예시:

> 질문: “전기차 산업의 미래는?”
> 
- MCP는 이를 다음처럼 분해함
    1. 시장 규모 관점
    2. 기술 혁신 관점
    3. 환경 정책 관점

➡ 각각의 질문 체인에 대해 **RAG를 적용하면**, 각 관점별 문서를 검색해 분석적인 응답이 가능해짐

---

## 🔄 세 기술의 관계 요약

| 기술 | 핵심 역할 | RAG와의 관계 |
| --- | --- | --- |
| **RAG** | 외부 지식 검색 + 생성 | 중심 기술 |
| **LangChain** | RAG 시스템 설계/구현 도구 | RAG를 실제로 연결/구현 |
| **MCP** | 사고를 분해하고 체인화 | RAG를 **다중 관점/단계별로 활용** 가능하게 해줌 |

📌 **LangChain은 시스템을 구축**,

📌 **RAG는 정보를 보강**,

📌 **MCP는 사고를 확장**하는 기술입니다.

---

## 🧠 최종 요약 정리

```
markdown
복사편집
사용자 질문 → MCP로 다중 체인 분해
          ↓
    각 체인에 대해 RAG 실행
          ↓
   문서 검색 + 생성형 응답
          ↓
     LangChain이 전체 흐름 연결

```

➡ 이 조합을 통해, 단순한 응답이 아닌

**깊이 있고, 정확하고, 구조화된 고품질 답변**이 가능합니다!